{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare dataset scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "VEHITYPE = \"/home/hthieu/AICityChallenge2019/data/Track2Data/train_vehicle_types\"\n",
    "OUT_FOLD = \"../data/vehi_type\"\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "all_classes = glob.glob(os.path.join(VEHITYPE,\"*\"))\n",
    "for x in all_classes:\n",
    "    files = glob.glob(os.path.join(x,\"*.jpg\"))\n",
    "    cls_id = x.split('/')[-1]\n",
    "    with open(os.path.join(OUT_FOLD,\"{}.csv\".format(str(cls_id))), \"w\") as fo:\n",
    "        for file in files:\n",
    "            file = os.path.basename(file)\n",
    "            par = file.split(\"_\")\n",
    "            if (par[0].isdigit() and par[1].isdigit() and \".jpg\" in par[2]):\n",
    "                fo.write(\"{},{},{}\\n\".format(par[0],par[2],par[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Test*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18291\n"
     ]
    }
   ],
   "source": [
    "with open('../data/image_test_by_group.txt') as fi:\n",
    "    lines = fi.readlines()\n",
    "    print(len(lines))\n",
    "    with open('../data/track2_test_by_group.csv', \"w\") as fo:\n",
    "        for line in lines:\n",
    "            if '.jpg' in line:\n",
    "                fo.write('1,'+line)\n",
    "        fo.close()\n",
    "    fi.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Query*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/query_list.txt') as fi:\n",
    "    lines = fi.readlines()\n",
    "    print(len(lines))\n",
    "    with open('data/track2_query.csv', \"w\") as fo:\n",
    "        for line in lines:\n",
    "            if '.jpg' in line:\n",
    "                fo.write('1,'+line)\n",
    "        fo.close()\n",
    "    fi.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Train and validate*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "import csv\n",
    "import os\n",
    "MAX_VALIDATE_\n",
    "\n",
    "with open(\"../data/track2_train_v3.csv\") as fi:\n",
    "    lines = fi.readlines()\n",
    "    with open(\"../data/track2_train_small.csv\", \"w\") as fo:\n",
    "        trains = []\n",
    "        for line in lines[:223]:\n",
    "            ins = line.strip().split(',')\n",
    "            trains += [ins[0] + ',' + x for x in ins[1:]]\n",
    "        shuffle(trains)\n",
    "        for train in trains:\n",
    "            fo.write(train + \"\\n\")\n",
    "        fo.close()\n",
    "    with open(\"../data/track2_validate.csv\", \"w\") as fo:\n",
    "        valds = []\n",
    "        for line in lines[223:]:\n",
    "            ins = line.strip().split(',')\n",
    "            valds += [ins[0] + ',' + x for x in ins[1:]]\n",
    "        shuffle(valds)\n",
    "        with open(\"../data/track2_validate_query.csv\", \"w\") as fo2:\n",
    "            for vald in valds[:1000]:\n",
    "                fo2.write(vald + \"\\n\")\n",
    "        for vald in valds[1000:]:\n",
    "            fo.write(vald + \"\\n\")\n",
    "        fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train csv_ver3\n",
    "import glob\n",
    "import os\n",
    "import csv\n",
    "img_view_dict = {}\n",
    "with open(\"../data/image_train_by_view.csv\") as img_view:\n",
    "    csv_reader = csv.reader(img_view, delimiter=',')\n",
    "    for row in csv_reader:\n",
    "        img_view_dict[str(row[0])] = str(row[1])\n",
    "\n",
    "with open(\"../data/track2_validate_query.csv\") as fi:\n",
    "    csv_reader = csv.reader(fi,delimiter=',')\n",
    "    with open(\"../data/track2_validate_query_v3.csv\", \"w\") as fo:\n",
    "        for info in csv_reader:\n",
    "            img_name = os.path.basename(info[1])\n",
    "            fo.write(\"{},{},{}\\n\".format(info[0],info[1],img_view_dict[img_name]))\n",
    "        fo.close()\n",
    "    fi.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test csv_ver3\n",
    "import glob\n",
    "import os\n",
    "import csv\n",
    "img_view_dict = {}\n",
    "with open(\"../data/image_test_by_view.csv\") as img_view:\n",
    "    csv_reader = csv.reader(img_view, c)\n",
    "    for row in csv_reader:\n",
    "        img_view_dict[str(row[0])] = str(row[1])\n",
    "\n",
    "with open(\"../data/track2_test.csv\") as fi:\n",
    "    csv_reader = csv.reader(fi,delimiter=',')\n",
    "    with open(\"../data/track2_test_v3.csv\", \"w\") as fo:\n",
    "        for info in csv_reader:\n",
    "            img_name = os.path.basename(info[1])\n",
    "            fo.write(\"{},{},{}\\n\".format(info[0],\"Track2Data/image_test/\"+info[1],img_view_dict[img_name]))\n",
    "        fo.close()\n",
    "    fi.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "INP_DIR = \"/home/hthieu/AICityChallenge2019/data/Track2Data/image_test_by_view\"\n",
    "OUT_DIR = \"/home/hthieu/AICityChallenge2019/data/Track2Data/image_test_by_view/image_test_by_group\"\n",
    "import glob\n",
    "import os\n",
    "from shutil import copyfile\n",
    "\n",
    "if not (os.path.exists(OUT_DIR)):\n",
    "    os.makedirs(OUT_DIR)\n",
    "imgs = glob.glob(os.path.join(INP_DIR,\"*/*.jpg\"))\n",
    "for img in imgs:\n",
    "    name = os.path.basename(img)\n",
    "    group = os.path.dirname(img).split(\"/\")[-1]\n",
    "    to_name = group + \"_\" + name\n",
    "    copyfile(img, os.path.join(OUT_DIR,to_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VERI DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "Veri_TRAIN = \"/home/hthieu/AICityChallenge2019/data/VeRi/image_test/\"\n",
    "trains = glob.glob(os.path.join(Veri_TRAIN,\"*.jpg\"))\n",
    "with open(\"../data/veri_test.csv\", \"w\") as fo:\n",
    "    for train in trains:\n",
    "        train = os.path.basename(train.strip())\n",
    "        info = train.split(\".\")[0].split(\"_\")\n",
    "        fo.write(\"{},VeRi/image_test/{}\\n\".format(1000 + int(info[0]),train.strip()))\n",
    "    fo.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge two files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = \"../data/track2_train_v2.csv\"\n",
    "file2 = \"../data/veri_train.csv\"\n",
    "file3 = \"../data/veri_test.csv\"\n",
    "lines = []\n",
    "files = [file1,file2,file3]\n",
    "for file in files:\n",
    "    with open(file) as fi:\n",
    "        lines += fi.readlines()\n",
    "from random import shuffle\n",
    "shuffle(lines)\n",
    "with open(\"../data/veri_train_test+track2_train_full.csv\", \"w\") as fo:\n",
    "    for line in lines:\n",
    "        fo.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109\n"
     ]
    }
   ],
   "source": [
    "with open(\"../data/track2_validate_query.csv\") as f:\n",
    "    lines = f.readlines()\n",
    "    a = {x.strip().split(\",\")[0] for x in lines}\n",
    "print(len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "INP_FOL = \"/home/hthieu/AICityChallenge2019/data/VeRi/image_query\"\n",
    "OUT_FILE = \"../data/veri_query.csv\"\n",
    "import glob\n",
    "import os\n",
    "imgs = glob.glob(os.path.join(INP_FOL,\"*.jpg\"))\n",
    "with open(OUT_FILE,\"w\") as fo:\n",
    "    for img in imgs:\n",
    "        name = os.path.basename(img)\n",
    "        info = name.split('.')[0].split(\"_\")\n",
    "        fo.write(\"{},{}\\n\".format(int(info[0]),name))\n",
    "    fo.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group camera\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rename instance_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "999\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "with open(\"../data/veri_train_test+track2_train_small.csv\") as fi:\n",
    "    csv_reader = csv.reader(fi, delimiter=',')\n",
    "    mapper = {}\n",
    "    idx = 0\n",
    "    with open(\"../data/veri_train_test+track2_train_small_v2.csv\",\"w\") as fo:\n",
    "        for info in csv_reader:\n",
    "            if (info[0] not in mapper):\n",
    "                mapper[info[0]] = idx\n",
    "                fo.write(\"{},{}\\n\".format(idx,info[1]) )\n",
    "                idx += 1\n",
    "            else:\n",
    "                 fo.write(\"{},{}\\n\".format(mapper[info[0]],info[1]) )\n",
    "        fo.close()\n",
    "    fi.close()\n",
    "print(len(mapper))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read from xml file:\n",
    "INP_FILE = \"/home/hthieu/AICityChallenge2019/data/Track2Data/train_label.xml\"\n",
    "IMG_ROOT = \"/home/hthieu/AICityChallenge2019/data/Track2Data/image_train\"\n",
    "OUT_DIR  = \"/home/hthieu/AICityChallenge2019/data/Track2Data/image_train_by_camera\"\n",
    "IMG_THUMBNAILS = \"/home/hthieu/AICityChallenge2019/data/Track2Data/image_train_thumbnails\"\n",
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "import glob\n",
    "from shutil import copyfile\n",
    "from shutil import rmtree\n",
    "\n",
    "if (os.path.exists(OUT_DIR)):\n",
    "    rmtree(OUT_DIR)\n",
    "\n",
    "xmlp = ET.XMLParser(encoding=\"utf-8\")\n",
    "tree = ET.parse(INP_FILE,parser=xmlp)\n",
    "root = tree.getroot()\n",
    "items = root[0].findall(\"Item\")\n",
    "\n",
    "fi = open('/home/hthieu/AICityChallenge2019/data/Track2Data/train_track.txt')\n",
    "lines = fi.readlines()\n",
    "views = []\n",
    "for i,line in enumerate(lines):\n",
    "    views += [line.strip().split(' ')]\n",
    "        \n",
    "done = []\n",
    "for item in items:\n",
    "    name = item.attrib[\"imageName\"]\n",
    "    camID = item.attrib[\"cameraID\"]\n",
    "    insID = item.attrib[\"vehicleID\"]\n",
    "    out_dir = os.path.join(OUT_DIR,camID)\n",
    "    if not (os.path.exists(out_dir)):\n",
    "        os.makedirs(out_dir)\n",
    "    t = camID + \"_\" + insID\n",
    "    if ( t not in done):\n",
    "        done+=[t]\n",
    "        for i,view in enumerate(views):\n",
    "            if name in view:\n",
    "                gr_id = str(i).zfill(3)+\".jpg\"\n",
    "                break\n",
    "        print(gr_id)\n",
    "        copyfile(os.path.join(IMG_THUMBNAILS,gr_id), os.path.join(out_dir,gr_id))\n",
    "\n",
    "print(len(items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27445\n",
      "(351, 'train_000248.jpg', 2880)\n"
     ]
    }
   ],
   "source": [
    "#new_track2_validate\n",
    "NEW_VAL_DIR = \"/home/hthieu/AICityChallenge2019/data/Track2Data/new_validate/\"\n",
    "TRAIN_DIR = \"/home/hthieu/AICityChallenge2019/data/Track2Data/image_train/\"\n",
    "TEST_DIR = \"/home/hthieu/AICityChallenge2019/data/Track2Data/image_test/\"\n",
    "\n",
    "import csv\n",
    "import os\n",
    "from shutil import copyfile\n",
    "\n",
    "if (not os.path.exists(NEW_VAL_DIR)):\n",
    "    os.makedirs(NEW_VAL_DIR)\n",
    "\n",
    "# with open(\"../data/track2_validate_v3.csv\") as fi:\n",
    "#     csv_reader = csv.reader(fi, delimiter=\",\")\n",
    "#     for info in csv_reader:\n",
    "#         copyfile(os.path.join(TRAIN_DIR, info[1]),\n",
    "#                 os.path.join(NEW_VAL_DIR, \"train_{}\".format(info[1])))\n",
    "\n",
    "# with open(\"../data/track2_test_v3.csv\") as fi:\n",
    "#     csv_reader = csv.reader(fi, delimiter=\",\")\n",
    "#     for info in csv_reader:\n",
    "#         copyfile(os.path.join(TEST_DIR, info[1]),\n",
    "#                 os.path.join(NEW_VAL_DIR, \"test_{}\".format(info[1])))\n",
    "\n",
    "all_imgs=[]\n",
    "with open(\"../data/track2_validate_v3.csv\") as fi:\n",
    "    csv_reader = csv.reader(fi, delimiter=\",\")\n",
    "    for info in csv_reader:\n",
    "        all_imgs.append((int(info[0]), \"train_{}\".format(info[1]), int(info[2]) + 1000))\n",
    "        \n",
    "with open(\"../data/track2_test_v3.csv\") as fi:\n",
    "    csv_reader = csv.reader(fi, delimiter=\",\")\n",
    "    for info in csv_reader:\n",
    "        all_imgs.append((999, \"test_{}\".format(info[1]), int(info[2])))\n",
    "\n",
    "with open(\"../data/track2_validate_new_v3.csv\", \"w\") as fo:\n",
    "    for x in all_imgs:\n",
    "        fo.write(\"{},{},{}\\n\".format(x[0],x[1],x[2]))\n",
    "print(len(all_imgs))\n",
    "print(all_imgs[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
